{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahekp05/Reinforcement-Learning-Projects/blob/main/Mario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jh0aoaTo_gU"
      },
      "source": [
        "## 1. Install Packages and Dependencies\n",
        "\n",
        "*   **gymnaisum**: toolkit for developing and comparing reinforcement learning algorithms. It provides various environments that simulate real-world scenarios, which are essential for testing and training RL models.\n",
        "*   **pygame**: writing video games; in reinforcement learning it is used to create custom environments\n",
        "*   **numpy**: library for numerical computation in python and provides support for arrays, matrices, and many mathematical functions essential for implementing and testing algorithms\n",
        "*   **imageio and imageio_ffmpeg**: libararies used to read and write images and videos -- useful to render environment and create visualization of our reinforcement learning model and training episodes on collabnotes as live redering is not possible\n",
        "*   **pyglet**: A cross-platform windowing and multimedia library -- used for rendering graphics in reinforcement learning environments\n",
        "*   **tqdm**: creates progress bars to help monitor progress of training and lenghty episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BpcgeLGloN4c",
        "outputId": "8a13ad03-148a-4fd5-bd70-c331bfd9f889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py) (2.0.2)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.11.2)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "\u001b[33mWARNING: gymnasium 1.2.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pickle5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pickle5\n",
            "Failed to build pickle5\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pickle5)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.3.0)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Collecting pyglet==1.5.1\n",
            "  Downloading pyglet-1.5.1-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Downloading pyglet-1.5.1-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-1.5.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ale-py\n",
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "!pip install pickle5\n",
        "!pip install imageio\n",
        "!pip install imageio_ffmpeg\n",
        "!pip install pyglet==1.5.1\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrzXR0i_3lK0"
      },
      "source": [
        "* stable_baselines3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdI9blvJ1w81",
        "outputId": "b8335c32-d040-4795-a7f3-2351a9456ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hneHmBFHsQj8"
      },
      "source": [
        "\n",
        "* **tensorflow**: A popular library for building and training machine learning models. tf.keras is TensorFlow's high-level API for defining and training neural networks\n",
        "* **sudo apt-get update**: Updates the package lists for the repositories, ensuring you get the latest information on the newest versions of packages and their dependencies.\n",
        "* **sudo apt-get install -y python3-opengl**: Installs the Python bindings for OpenGL, which are necessary for running graphical applications that use OpenGL.\n",
        "* **sudo apt-get install -y ffmpeg xvfb**: Installs FFmpeg, a complete solution for recording, converting, and streaming audio and video, and Xvfb, a display server that performs graphical operations in memory without showing any screen output.\n",
        "* **pip3 install pyvirtualdisplay**: Installs the pyvirtualdisplay package using pip, which allows you to create and manage virtual displays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzinxiDB3MZf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2i5xzIkr4uE",
        "outputId": "d5df0042-655f-4c32-eee6-68564d3e6a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,161 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,775 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,197 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,066 kB]\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,273 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,514 kB]\n",
            "Fetched 32.2 MB in 8s (4,251 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libglu1-mesa\n",
            "Suggested packages:\n",
            "  libgle3 python3-numpy\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libglu1-mesa python3-opengl\n",
            "0 upgraded, 3 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 824 kB of archives.\n",
            "After this operation, 8,092 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Fetched 824 kB in 2s (356 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-opengl\n",
        "!apt install ffmpeg xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaNIW-xqrBp-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(),9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jK7IWiZq03N"
      },
      "source": [
        "##2. Import Dependencies and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFiDp6vgnoAR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "759a9e1c-b038-4eb7-e6e9-2c450659b38b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pickle5'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-969076384.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpickle5\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pickle5'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "import tqdm\n",
        "\n",
        "import pickle5 as pickle\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpbfSxUS17OU"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEQSPj1F34KH"
      },
      "source": [
        "* **Sequential**: A type of model in Keras where layers are stacked sequentially.\n",
        "* **Dense**: A fully connected layer where each neuron is connected to every neuron in the previous layer.\n",
        "* **Conv2D**: A 2D convolutional layer, which is commonly used for processing image data.\n",
        "* **Flatten**: A layer that flattens the input, converting it from a multi-dimensional tensor to a 1D tensor.\n",
        "* **Adam**: An optimization algorithm used for training the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkNSl6-P3Jz6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFEOv3B_rQi7"
      },
      "source": [
        "##3. Virtual Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5Id6--jrU_f"
      },
      "outputs": [],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0,size=(1400,900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9g-vWq9s7cb"
      },
      "source": [
        "##4. Create Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCdlGhgWvh_1"
      },
      "source": [
        "*Initialize Environment*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPfCinFps0-B"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"ALE/MarioBros-v5\", render_mode = \"rgb_array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBNR9Zwbw_Ff"
      },
      "source": [
        "*Environment State Space*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBJEpSv_wN7z"
      },
      "outputs": [],
      "source": [
        "state_space = env.observation_space\n",
        "print(\"State Space:\", state_space)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GebXUnbOxDW_"
      },
      "source": [
        "(0,255) -> (min, max) number of elements observation array can take\n",
        "\n",
        "(210,160,3) -> (height of image [pix], width of image [pix], color channels #)\n",
        "\n",
        "(uint8) -> unsigned 8-bit int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsbqCGVIxxBU"
      },
      "source": [
        "*Environment Action Space*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtHzxcVSxtCC"
      },
      "outputs": [],
      "source": [
        "action_space = env.action_space.n\n",
        "print(\"Action Space:\", action_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohEWPiW_x-BC"
      },
      "source": [
        "18 possible action spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7sbPKFjyOve"
      },
      "source": [
        "#####Initialize Q-table\n",
        "* represents the expected future rewards for state-action pairs and requires discrete states and actions.\n",
        "\n",
        "NOT SIMPLE FOR BOX (CONTINOUS ENVIRONMENTS) AS USUALLY FOR DISCRETE SPACES\n",
        "\n",
        "INSTEAD USE function approximation methods like Q-learning with nueral  networks to estimate q-values\n",
        "1. Deep Q-learning (DQN) -- best for continious state spaces and discrete action spaces\n",
        "2. Policy Graident Methods\n",
        "3. Actor-Critic Methods\n",
        "4. Deep Deterministic Policy Gradient\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCajHwE30lzR"
      },
      "source": [
        "Deep Q-learning (DQN) Key Components\n",
        "1. Q-network - approximates the Q-value\n",
        "2. Experience Relay - buffer that stores past experiences (state, action, reward, next state)\n",
        "      * Training on random samples from this buffer helps in stabilizing the learning process by breaking the correlation between consecutive experiences.\n",
        "\n",
        "3. Target Network - updated less frequently. It helps to stabilize the training process by providing consistent target Q-values for the Bellman update\n",
        "4. Epsilon Greedy Strategy - A policy for balancing exploration and exploitation\n",
        "\n",
        "How DQN Handles Continuous State Spaces\n",
        "* Convolutional Neural Networks (CNNs): to process the image data\n",
        "    * CNNs are effective at extracting features from image data and learning spatial hierarchies.\n",
        "* State Representation: to produce feature maps\n",
        "    * These feature maps are then used to predict Q-values for discrete actions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8CtrDzsyXMx"
      },
      "outputs": [],
      "source": [
        "def initialize_dq_nueral_network(state_shape, action_num):\n",
        "  \"\"\"\n",
        "    Initialize a Deep Q-Network (DQN) neural network for reinforcement learning.\n",
        "\n",
        "    Parameters:\n",
        "    - state_shape: Tuple representing the shape of the input state (e.g., image dimensions).\n",
        "    - action_num: Integer representing the number of possible actions in the environment.\n",
        "\n",
        "    Returns:\n",
        "    - model: A compiled TensorFlow Keras Sequential model.\n",
        "    \"\"\"\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  #Add convolution layers for image data\n",
        "  #(input dimensions, kernel size, strides,activation function, state_shape)\n",
        "\n",
        "  # Add a convolutional layer to process image data\n",
        "  model.add(Conv2D(32,(8,8), strides = (4,4), activation = \"relu\", input_shape=state_shape))\n",
        "  # Add a second convolutional layer\n",
        "  model.add(Conv2D(64,(4,4),strides = (2,2), activation = \"relu\"))\n",
        "  # Add a third convolutional layer\n",
        "  model.add(Conv2D(64,(3,3), activation = \"relu\"))\n",
        "\n",
        "  # Flatten the output from the convolutional layers --- convert the 3D tensor into a 1D tensor for the fully connected\n",
        "  model.add(Flatten())\n",
        "\n",
        "  #Add a fully connected (dense) layer\n",
        "  model.add(Dense(512, activation = \"relu\"))\n",
        "\n",
        "  #output layers: one q-value for each action\n",
        "  #(total possible actions = # of nuerons,  linear activation to ouput q-value for each action)\n",
        "  model.add(Dense(action_num, activation = \"linear\"))\n",
        "\n",
        "  #compile model -- Adam optimizer with a learning rate of 0.001\n",
        "  #Mean Squared Error (MSE) loss function for training the model\n",
        "  model.compile(optimizer = Adam(learning_rate=0.001), loss = \"mse\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqToih8456F-"
      },
      "source": [
        "model.add(Conv2D(32,(8,8), strides = (4,4), activation = \"relu\", state_space=state_space))\n",
        "* 32: Number of filters (or kernels) in this convolutional layer.\n",
        "* (8, 8): Size of the convolutional kernels.\n",
        "* strides=(4, 4): The stride of the convolution --  determines how much the filter moves across the input image.\n",
        "* activation='relu': Activation function used to introduce non-linearity.\n",
        "    * ReLU (Rectified Linear Unit) helps the network learn complex patterns.\n",
        "* input_shape=input_shape: Specifies the shape of the input data\n",
        "\n",
        "----\n",
        "* Input Dimensions: Directly from your data.\n",
        "* Kernel Size: Selected based on design choices and experimentation.\n",
        "* Strides: Chosen based on how aggressively you want to reduce spatial dimensions.\n",
        "* Padding: Affects whether the output size is reduced or preserved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL7X2Lb27uXn"
      },
      "source": [
        "* Flatten Layer: Flattens the 3D output of the convolutional layers into a 1D vector.\n",
        "* Dense Layer: Fully connected layer with 512 neurons and ReLU activation.\n",
        "* Output Layer: Dense layer with a number of neurons equal to the number of possible actions, with linear activation.\n",
        "* Compile: Compiles the model using the Adam optimizer and mean squared error loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jJEAzdw9O6O"
      },
      "outputs": [],
      "source": [
        "state_shape = env.observation_space.shape\n",
        "action_num = env.action_space.n\n",
        "\n",
        "Qnetwork_mario = initialize_dq_nueral_network(state_shape=state_shape, action_num=action_num)\n",
        "print(Qnetwork_mario.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RBQoeYpttsv"
      },
      "source": [
        "##5.Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGPr4rQsh7sX"
      },
      "source": [
        "####1. create replay buffer\n",
        "* deque DS used to store and manage agent's past experiences during interaction with environment\n",
        "\n",
        "Each experience stored as tuple in form of (state, actio, reward, next_stae, done)\n",
        "\n",
        "*Randomization helps break correlation between consecutive episodes, stabilizing training process\n",
        "\n",
        "*Atend can learn from past experience where experiences are costly or slow to accumulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7zWXtC9ketY"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "class ReplayBuffer:\n",
        "  def __init__(self, max_size):\n",
        "    #older experiences automatically removed when buffer reaches size\n",
        "    self.buffer = deque(maxlen = max_size)\n",
        "\n",
        "  #add new experience to buffer\n",
        "  def add(self, experience):\n",
        "    #if full, oldest experience discarded\n",
        "    self.buffer.append(experience)\n",
        "\n",
        "  #sample batch of experiences from buffer\n",
        "  def sample(self, batch_size):\n",
        "    #randomly samples batch which is used to train nueral network [note: np = numpy]\n",
        "    indices = np.random.choice(len(self.buffer),batch_size, replace =False)\n",
        "    batch = [self.buffer[idx] for idx in indices]\n",
        "\n",
        "    states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
        "    return states, actions, rewards, next_states, dones\n",
        "\n",
        "  #return number of experiences in buffer\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSy8WmSbmocu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Ur7elwmjnN"
      },
      "source": [
        "####2. Training with Experience Relay\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5CaP4ZmoV_Y"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy_policy(Qnetwork, state, epsilon, action_space):\n",
        "  rand_num = np.random.rand()\n",
        "\n",
        "  if rand_num <= epsilon:\n",
        "    action = np.random.randint(0,action_space) #Explore\n",
        "   # print(f\"Exploration: action chosen randomly: {action}\")\n",
        "  else: #Exploit\n",
        "    state_input = np.expand_dims(state, axis=0)\n",
        "    #print(f\"State shape before prediction: {state_input.shape}\")\n",
        "    Qvalues = Qnetwork.predict(state_input)\n",
        "    #print(f\"Q-values predicted: {Qvalues}\")\n",
        "    action = np.argmax(Qvalues[0])\n",
        "    #print(f\"Exploitation: action chosen by Q-network: {action}\")\n",
        "\n",
        "  return action\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6biTE5qiuxG9"
      },
      "source": [
        "Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK_FcfQ-uwvi"
      },
      "outputs": [],
      "source": [
        "#training parameters\n",
        "n_training_episodes = 10\n",
        "learning_rate = 0.7\n",
        "\n",
        "#Evaluation parameters\n",
        "n_eval_episodes = 100\n",
        "\n",
        "#Environment parameters\n",
        "env_id = \"ALE/MarioBros-v5\"\n",
        "gamma = 0.99\n",
        "\n",
        "#Exploration parameters\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.995\n",
        "min_epsilon = 0.01\n",
        "target_update_freq = 10\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6XB4crRm1gA"
      },
      "outputs": [],
      "source": [
        "def train_dqn(env, q_network, target_network, replay_buffer, episodes, batch_size, gamma,\n",
        "              epsilon, epsilon_decay, min_epsilon, target_update_freq):\n",
        "    for episode in tqdm(range(episodes)):\n",
        "        state = env.reset()\n",
        "        if isinstance(state, tuple):\n",
        "            state = state[0]\n",
        "        state = np.array(state)  # Ensure state is a numpy array\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            action = epsilon_greedy_policy(q_network, state, epsilon, action_space)\n",
        "            next_state, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            if isinstance(next_state, tuple):\n",
        "                next_state = next_state[0]\n",
        "            next_state = np.array(next_state)  # Ensure next_state is a numpy array\n",
        "            replay_buffer.add((state, action, reward, next_state, done))\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "            if len(replay_buffer) > batch_size:\n",
        "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
        "                targets = q_network.predict(states)\n",
        "                target_vals = target_network.predict(next_states)\n",
        "                for i in range(batch_size):\n",
        "                    if dones[i]:\n",
        "                        targets[i][actions[i]] = rewards[i]\n",
        "                    else:\n",
        "                        targets[i][actions[i]] = rewards[i] + gamma * np.amax(target_vals[i])\n",
        "                q_network.fit(states, targets, epochs=1, verbose=0)\n",
        "\n",
        "            if epsilon > min_epsilon:\n",
        "                epsilon *= epsilon_decay\n",
        "\n",
        "        if episode % target_update_freq == 0:\n",
        "            target_network.set_weights(q_network.get_weights())\n",
        "\n",
        "        print(f\"Episode: {episode}/{episodes}, Total reward: {total_reward}, Epsilon: {epsilon:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6RCjJ3mwpju"
      },
      "source": [
        "####3. Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsSJ-dast2wy"
      },
      "source": [
        "##6. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qn_enMUGwtSp"
      },
      "outputs": [],
      "source": [
        "#Initialize environment\n",
        "env1 = gym.make(env_id, render_mode = \"rgb_array\")\n",
        "state_shape = env.observation_space.shape\n",
        "action_num = env.action_space.n\n",
        "\n",
        "#Initialize Q-netwrok and target netwrok\n",
        "Qnetwork_mario = initialize_dq_nueral_network(state_shape, action_num)\n",
        "target_network = initialize_dq_nueral_network(state_shape, action_num)\n",
        "target_network.set_weights(Qnetwork_mario.get_weights())\n",
        "\n",
        "#Initialize replay buffer\n",
        "replay_buffer = ReplayBuffer(1000)\n",
        "\n",
        "train_dqn(env1, Qnetwork_mario, target_network, replay_buffer, n_training_episodes, batch_size, gamma,\n",
        "          epsilon, epsilon_decay, min_epsilon, target_update_freq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKATCWCcdAql"
      },
      "outputs": [],
      "source": [
        "# Define the model dictionary\n",
        "model = {\n",
        "    \"env_id\": env_id,\n",
        "    \"state_shape\": state_shape,\n",
        "    \"action_num\": action_num,\n",
        "    \"Qnetwork_mario\": Qnetwork_mario,\n",
        "    \"target_network\": target_network,\n",
        "    \"replay_buffer\": replay_buffer,\n",
        "    \"n_training_episodes\": n_training_episodes,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"n_eval_episodes\": n_eval_episodes,\n",
        "    \"gamma\": gamma,\n",
        "    \"epsilon\": epsilon,\n",
        "    \"epsilon_decay\": epsilon_decay,\n",
        "    \"min_epsilon\": min_epsilon,\n",
        "    \"target_update_freq\": target_update_freq,\n",
        "    \"batch_size\": batch_size\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfKjMw4udb4n"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "def record_video(env, Qnetwork, out_directory, fps=1, max_steps=20):\n",
        "    \"\"\"\n",
        "    Generate a replay video of the agent using a Q-network.\n",
        "    :param env: Gym environment\n",
        "    :param Qnetwork: Q-network of our agent\n",
        "    :param out_directory: Directory to save the video\n",
        "    :param fps: Frames per second (default is 1 for taxi-v3)\n",
        "    :param max_steps: Maximum steps for recording\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    state, info = env.reset(seed=random.randint(0, 500))\n",
        "    state = np.array(state)\n",
        "\n",
        "    # Render without mode if 'mode' is not supported\n",
        "    img = env.render()\n",
        "    images.append(img)\n",
        "    step_count = 0\n",
        "\n",
        "    while not (terminated or truncated) and step_count < max_steps:\n",
        "        # Use Q-network to select the action\n",
        "        state_input = np.expand_dims(state, axis=0)\n",
        "        q_values = Qnetwork.predict(state_input)\n",
        "        action = np.argmax(q_values[0])\n",
        "\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        next_state = np.array(next_state)\n",
        "\n",
        "        img = env.render()\n",
        "        images.append(img)\n",
        "        step_count += 1\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # Save the video\n",
        "    imageio.mimsave(out_directory, [np.array(img) for img in images], fps=fps)\n",
        "\n",
        "# Example usage\n",
        "video_name = \"replay.mp4\"\n",
        "record_video(env, model[\"Qnetwork_mario\"], video_name, fps=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMgH3M-wefdC"
      },
      "outputs": [],
      "source": [
        " video_name = \"replay.mp4\"\n",
        " record_video(env, model[\"Qnetwork_mario\"], video_name,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQfvkHWSe-LY"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('replay.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1jK7IWiZq03N",
        "YFEOv3B_rQi7",
        "R7sbPKFjyOve"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOgZCU3YLeLb8WQpXg2fhk1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}